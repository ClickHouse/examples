{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa06f8c3-e13f-4f03-97a0-8565699ae34a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T12:39:00.824020Z",
     "iopub.status.busy": "2025-05-29T12:39:00.823521Z",
     "iopub.status.idle": "2025-05-29T12:39:00.829370Z",
     "shell.execute_reply": "2025-05-29T12:39:00.828238Z",
     "shell.execute_reply.started": "2025-05-29T12:39:00.823981Z"
    }
   },
   "source": [
    "# How to build an AI Agent with OpenAI and the ClickHouse MCP Server\n",
    "\n",
    "In this notebook we'll see how to build an [Open AI](https://github.com/openai/openai-agents-python) AI agent that can interact with [ClickHouse's SQL playground](https://sql.clickhouse.com/) using [ClickHouse's MCP Server](https://github.com/ClickHouse/mcp-clickhouse).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf3a5a9-9d68-4591-aad1-7c8855a3cc8c",
   "metadata": {},
   "source": [
    "## Install libraries\n",
    "We need to install the Agno library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb744032-3e34-4970-bcd2-96321009dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b3bbf6-68f3-4f6f-bf0b-5b7861748250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T09:34:46.246695Z",
     "iopub.status.busy": "2025-06-04T09:34:46.246062Z",
     "iopub.status.idle": "2025-06-04T09:34:49.473035Z",
     "shell.execute_reply": "2025-06-04T09:34:49.472465Z",
     "shell.execute_reply.started": "2025-06-04T09:34:46.246650Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q openai-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ccc86-83c1-4b81-a105-4b031da79607",
   "metadata": {},
   "source": [
    "## Setup credentials\n",
    "Let's provide our Anthropic API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd9d57e-448c-4ab2-a947-a461d76176b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T09:35:13.637801Z",
     "iopub.status.busy": "2025-06-04T09:35:13.637274Z",
     "iopub.status.idle": "2025-06-04T09:35:13.643038Z",
     "shell.execute_reply": "2025-06-04T09:35:13.642266Z",
     "shell.execute_reply.started": "2025-06-04T09:35:13.637765Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06f52279-865d-4fef-92b7-d9743473f466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T09:43:53.583060Z",
     "iopub.status.busy": "2025-06-04T09:43:53.582038Z",
     "iopub.status.idle": "2025-06-04T09:43:55.836966Z",
     "shell.execute_reply": "2025-06-04T09:43:55.836451Z",
     "shell.execute_reply.started": "2025-06-04T09:43:53.582998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498c1b8-b762-45a1-9165-55957f2cecad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:29:32.100459Z",
     "iopub.status.busy": "2025-05-29T14:29:32.100270Z",
     "iopub.status.idle": "2025-05-29T14:29:32.103177Z",
     "shell.execute_reply": "2025-05-29T14:29:32.102622Z",
     "shell.execute_reply.started": "2025-05-29T14:29:32.100446Z"
    }
   },
   "source": [
    "We'll also define the credentials to connect to the ClickHouse SQL playground:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6845f3db-8f6a-41c3-bae9-6c4c1b6bde1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T09:41:27.059204Z",
     "iopub.status.busy": "2025-06-04T09:41:27.058433Z",
     "iopub.status.idle": "2025-06-04T09:41:27.066733Z",
     "shell.execute_reply": "2025-06-04T09:41:27.065623Z",
     "shell.execute_reply.started": "2025-06-04T09:41:27.059073Z"
    }
   },
   "outputs": [],
   "source": [
    "env = {\n",
    "    \"CLICKHOUSE_HOST\": \"sql-clickhouse.clickhouse.com\",\n",
    "    \"CLICKHOUSE_PORT\": \"8443\",\n",
    "    \"CLICKHOUSE_USER\": \"demo\",\n",
    "    \"CLICKHOUSE_PASSWORD\": \"\",\n",
    "    \"CLICKHOUSE_SECURE\": \"true\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2812b1-1ee9-4669-bfb1-ffabaeb3d597",
   "metadata": {},
   "source": [
    "## Initialize MCP Server and OpenAI agent\n",
    "\n",
    "Lets configure the ClickHouse MCP Server to point at the ClickHouse SQL playground and also initialize our OpenAI agent and ask it a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b89b57c-8740-4426-a058-e213fd2daf8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T10:21:31.548416Z",
     "iopub.status.busy": "2025-06-04T10:21:31.547873Z",
     "iopub.status.idle": "2025-06-04T10:21:31.552570Z",
     "shell.execute_reply": "2025-06-04T10:21:31.551684Z",
     "shell.execute_reply.started": "2025-06-04T10:21:31.548385Z"
    }
   },
   "outputs": [],
   "source": [
    "from agents.mcp import MCPServer, MCPServerStdio\n",
    "from agents import Agent, Runner, trace\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c8527b4-ccda-4203-a2d2-dc3169b251c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T10:23:09.919068Z",
     "iopub.status.busy": "2025-06-04T10:23:09.918665Z",
     "iopub.status.idle": "2025-06-04T10:23:09.929113Z",
     "shell.execute_reply": "2025-06-04T10:23:09.928568Z",
     "shell.execute_reply.started": "2025-06-04T10:23:09.919043Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_render_chunk(chunk):\n",
    "    \"\"\"Simple version that just filters important events\"\"\"\n",
    "    \n",
    "    # Tool calls\n",
    "    if (hasattr(chunk, 'type') and \n",
    "        chunk.type == 'run_item_stream_event'):\n",
    "        \n",
    "        if chunk.name == 'tool_called':\n",
    "            tool_name = chunk.item.raw_item.name\n",
    "            args = chunk.item.raw_item.arguments\n",
    "            print(f\"🔧 Tool: {tool_name}({args})\")\n",
    "        \n",
    "        elif chunk.name == 'tool_output':\n",
    "            try:\n",
    "                # Handle both string and already-parsed output\n",
    "                if isinstance(chunk.item.output, str):\n",
    "                    output = json.loads(chunk.item.output)\n",
    "                else:\n",
    "                    output = chunk.item.output\n",
    "                \n",
    "                # Handle both dict and list formats\n",
    "                if isinstance(output, dict):\n",
    "                    if output.get('type') == 'text':\n",
    "                        text = output['text']\n",
    "                        if 'Error' in text:\n",
    "                            print(f\"❌ Error: {text}\")\n",
    "                        else:\n",
    "                            print(f\"✅ Result: {text[:100]}...\")\n",
    "                elif isinstance(output, list) and len(output) > 0:\n",
    "                    # Handle list format\n",
    "                    first_item = output[0]\n",
    "                    if isinstance(first_item, dict) and first_item.get('type') == 'text':\n",
    "                        text = first_item['text']\n",
    "                        if 'Error' in text:\n",
    "                            print(f\"❌ Error: {text}\")\n",
    "                        else:\n",
    "                            print(f\"✅ Result: {text[:100]}...\")\n",
    "                else:\n",
    "                    # Fallback - just print the raw output\n",
    "                    print(f\"✅ Result: {str(output)[:100]}...\")\n",
    "                    \n",
    "            except (json.JSONDecodeError, AttributeError, KeyError) as e:\n",
    "                # Fallback to raw output if parsing fails\n",
    "                print(f\"✅ Result: {str(chunk.item.output)[:100]}...\")\n",
    "        \n",
    "        elif chunk.name == 'message_output_created':\n",
    "            try:\n",
    "                content = chunk.item.raw_item.content\n",
    "                if content and len(content) > 0:\n",
    "                    print(f\"💬 Response: {content[0].text}\")\n",
    "            except (AttributeError, IndexError):\n",
    "                print(f\"💬 Response: {str(chunk.item)[:100]}...\")\n",
    "    \n",
    "    # Text deltas for streaming\n",
    "    elif (hasattr(chunk, 'type') and \n",
    "          chunk.type == 'raw_response_event' and\n",
    "          hasattr(chunk, 'data') and \n",
    "          hasattr(chunk.data, 'type') and\n",
    "          chunk.data.type == 'response.output_text.delta'):\n",
    "        print(chunk.data.delta, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daba4d76-405b-4b31-8577-9b6436de4c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T10:23:11.389618Z",
     "iopub.status.busy": "2025-06-04T10:23:11.389334Z",
     "iopub.status.idle": "2025-06-04T10:23:39.574798Z",
     "shell.execute_reply": "2025-06-04T10:23:39.574509Z",
     "shell.execute_reply.started": "2025-06-04T10:23:11.389603Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running: What's the biggest GitHub project so far in 2025?\n",
      "🔧 Tool: list_databases({})\n",
      "✅ Result: amazon\n",
      "bluesky\n",
      "country\n",
      "covid\n",
      "default\n",
      "dns\n",
      "environmental\n",
      "food\n",
      "forex\n",
      "geo\n",
      "git\n",
      "github\n",
      "hackernews\n",
      "imdb\n",
      "log...\n",
      "🔧 Tool: list_tables({\"database\":\"github\"})\n",
      "✅ Result: {\n",
      "  \"database\": \"github\",\n",
      "  \"name\": \"actors_per_repo\",\n",
      "  \"comment\": \"\",\n",
      "  \"columns\": [\n",
      "    {\n",
      "      \"...\n",
      "🔧 Tool: run_select_query({\"query\":\"SELECT repo_name, MAX(stars) FROM github.top_repos_mv\"})\n",
      "✅ Result: {\n",
      "  \"status\": \"error\",\n",
      "  \"message\": \"Query failed: HTTPDriver for https://sql-clickhouse.clickhouse....\n",
      "🔧 Tool: run_select_query({\"query\":\"SELECT repo_name, stars FROM github.top_repos ORDER BY stars DESC LIMIT 1\"})\n",
      "✅ Result: {\n",
      "  \"repo_name\": \"sindresorhus/awesome\",\n",
      "  \"stars\": 402893\n",
      "}...\n",
      "The biggest GitHub project in 2025, based on stars, is \"[sindresorhus/awesome](https://github.com/sindresorhus/awesome)\" with 402,893 stars.💬 Response: The biggest GitHub project in 2025, based on stars, is \"[sindresorhus/awesome](https://github.com/sindresorhus/awesome)\" with 402,893 stars.\n"
     ]
    }
   ],
   "source": [
    "async with MCPServerStdio(\n",
    "        name=\"ClickHouse SQL Playground\",\n",
    "        params={\n",
    "            \"command\": \"uv\",\n",
    "            \"args\": [\n",
    "                'run',\n",
    "                '--with', 'mcp-clickhouse',\n",
    "                '--python', '3.13',\n",
    "                'mcp-clickhouse'\n",
    "            ],\n",
    "            \"env\": env\n",
    "        }, client_session_timeout_seconds = 60\n",
    "    ) as server:\n",
    "        agent = Agent(\n",
    "            name=\"Assistant\",\n",
    "            instructions=\"Use the tools to query ClickHouse and answer questions based on those files.\",\n",
    "            mcp_servers=[server],\n",
    "        )\n",
    "\n",
    "        message = \"What's the biggest GitHub project so far in 2025?\"\n",
    "        print(f\"\\n\\nRunning: {message}\")\n",
    "        with trace(\"Biggest project workflow\"): \n",
    "            result = Runner.run_streamed(starting_agent=agent, input=message, max_turns=20)\n",
    "            async for chunk in result.stream_events():\n",
    "                simple_render_chunk(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
